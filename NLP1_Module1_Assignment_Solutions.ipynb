{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP1_Module1_Assignment_Solutions.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UcgNSIvuIQqK"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>\n","\n","**<center><h3>NLP 1 Module 1 Assignment Solutions</h3></center>**"]},{"cell_type":"markdown","metadata":{"id":"_ATbV26DaIt4"},"source":["----\n","# **Table of Contents**\n","----\n","\n","**1.** [**Problem Statement**](#section1)<br> \n","**2.** [**Import Libraries**](#section2)<br> \n","**3.** [**Data Description**](#section3)<br> \n","**4.** [**Text Preprocessing**](#section4)<br>\n","   - **4.1** [**Lowercasing**](#section401)\n","   - **4.2** [**Word Tokenisation**](#section402)\n","   - **4.3** [**Stopwords Removal**](#section403)\n","   - **4.4** [**Stemming**](#section404)\n","   - **4.5** [**Lemmantization**](#section405)\n","   - **4.6** [**Part of Speech Tagging**](#section406)\n","\n","**5.** [**Name Entity Recognition**](#section5)<br>\n","**6.** [**Conclusion**](#section6)<br>"]},{"cell_type":"markdown","metadata":{"id":"BmlyYG19ckwb"},"source":["---\n","<a id=section1></a>\n","# **1. Problem Statement**\n","----"]},{"cell_type":"markdown","metadata":{"id":"PivlYqm-lni5"},"source":["- To apply serval **Text Preprocessing** techniques on **text corpus**.\n","\n","- In order to use **ML techniques** on text data we need to convert **text** data to **numerical** values. For that we need to **apply** various text **preprocessing** techniques. \n","\n","- **Preprocess** your text simply **means** to bring your text into a form that is **predictable** and **analyzable** for your task."]},{"cell_type":"markdown","metadata":{"id":"e2bYQTRxcqug"},"source":["----\n","<a id=section2></a>\n","# **2. Import Libraries**\n","----"]},{"cell_type":"code","metadata":{"id":"4GbZy5ttLGhl"},"source":["import nltk\n","from nltk.corpus import brown\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk import sent_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem import SnowballStemmer\n","from nltk import FreqDist"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PsZ9P0RKgjR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620753023752,"user_tz":-330,"elapsed":1184,"user":{"displayName":"Abhinav Jangir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5BRKsvqkQkWg693HbUASD9zTwMPl3TXIK2r0eNw=s64","userId":"14394398945056327842"}},"outputId":"30c6a452-3dab-46f4-caba-983ef0d4f4c1"},"source":["import warnings\n","warnings.filterwarnings(action = 'ignore')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"k2ZnpzYccuLE"},"source":["----\n","<a id=section3></a>\n","# **3. Data Description**\n","----"]},{"cell_type":"markdown","metadata":{"id":"VaTZnCyPiK1U"},"source":["- We are using **Brown Corpra** for our problem.\n","\n","- The **corpus** consists of **one million words** of **American English** texts printed in **1961**.\n","\n","- This corpus contains text from **500** sources, and the sources have been **categorised** by genre, such as **news**, **editorial**, and so on.\n","\n","**Example document for each section of the Brown Corpus**: \n","\n","<br>  \n","<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/image/Sqweeks%20image/text_corpra_brown.png\" width=\"1000\" height=\"400\" /></center>\n","\n","<br>  "]},{"cell_type":"markdown","metadata":{"id":"nea3JVmLKO2Y"},"source":["**<h4>Question 1:** How we can download the Brown corpus using NLTK?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use **`nltk.download()`** to download any corpus.\n","\n","- Give `brown` as parameter.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"SQap_buhKOJj"},"source":["def download_brown():\n","    nltk.download('brown')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgcbjbPq5Qkq","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1578386701660,"user_tz":-330,"elapsed":3356,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"837da483-22a4-4bc4-c0db-2b7fe44f5ab9"},"source":["download_brown()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"93FwOKYqUGZY"},"source":["- Printing **categories** in **text corpus**:"]},{"cell_type":"code","metadata":{"id":"OtyqLTODLBST"},"source":["def print_brown_categories():\n","    print(brown.categories())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjolvj7BLBQC","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578386713849,"user_tz":-330,"elapsed":3159,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"23d86452-9d5a-442a-b148-c09fe84a20f6"},"source":["print_brown_categories()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LhoZQlCycwzQ"},"source":["----\n","<a id=section4></a>\n","# **4. Text Preprocessing**\n","----"]},{"cell_type":"markdown","metadata":{"id":"7bX9f6yGpQLU"},"source":[" \n","- We know that in order to deal with **textual data** with **Machine Learning** we need to **convert** it to **numeric** form.\n","\n","- But before applying **embedding**(to convert text to numeric form) **text data** should be **clean** and **preprocessed**.\n","\n","-  The **pre-processing** steps for a problem **depend** mainly on the **domain** and the **problem**.\n","\n","- The various text **preprocessing** steps are:\n","  - **Lower Casing Text**\n","  - **Tokenization**\n","  - **Removal of Punctuations**\n","  - **Removal of Stopwords**\n","  - **Removal of Frequent words**\n","  - **Stemming**\n","  - **Lemmatization**\n","  - **Removal of Emojis**\n","  - **Conversion of Emojis to words**\n","  - **Removal of URLs**\n","  - **Spelling correction**"]},{"cell_type":"markdown","metadata":{"id":"ioRG5OD5XsyU"},"source":["<a id=section401></a>\n","### **4.1 Lowercasing**"]},{"cell_type":"markdown","metadata":{"id":"u2UPgzhkd8BA"},"source":["- Words like \"**INSAID**\", \"**Insaid**\" and \"**insaid**\" means same.\n","\n","- But without **lower case** we need **3** word vector to represent them in **vector space**.\n","\n","- It will also helps in **reducing** size of text **data vocabulary**.\n"]},{"cell_type":"code","metadata":{"id":"7rn03HhwL0Tl"},"source":["text =  \"The capital of India is New Delhi.\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOdOOdejLVer"},"source":["**<h4>Question 2:** How we can convert our Text to lower case?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use **`text.lower()`** to lowercase text where text is input word/sentence  string.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"WPqTFtURL2AB"},"source":["def to_lower(text):\n","    lower_text = text.lower()\n","\n","    return lower_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RqDGirKjLXBe"},"source":["lower_text = to_lower(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lFFUuXzwMB9a","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578386896020,"user_tz":-330,"elapsed":2881,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"c4e40dbf-e78b-47dc-dadd-0cbf83fac139"},"source":["print(lower_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["the capital of india is new delhi.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWIURiM5fyrj"},"source":["\n","<a id=section401></a>\n","### **4.2 Word Tokenisation**"]},{"cell_type":"markdown","metadata":{"id":"LmTtmvkof4XI"},"source":["- Tokenization is the process of **splitting** the given text into smaller pieces called **tokens**.\n","\n","- Words, numbers, punctuation marks, and others can be considered as tokens.\n","\n","- For example if input sentence is \"**International School of AI and Data Science**\" so after **tokenisation** output will be **`[International, School, of, AI, and, Data, Science]`**\n"]},{"cell_type":"code","metadata":{"id":"XNm-VCZQMby5"},"source":["text =  \"The capital of India is New Delhi.\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ba2nwdVyMMpS"},"source":["**<h4>Question 3:** How to perform Word Tokenisation on a sentence?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Apply **`nltk.word_tokenize()`** on `text` variable to tokenize text.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"bXutrHhAMbw3"},"source":["def tokenize_fn(text):\n","    word_tokens = nltk.word_tokenize(text)\n","\n","    return word_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uhrOMsdMbsE"},"source":["word_tokens = tokenize_fn(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxwVT6FMMzVB","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578387072597,"user_tz":-330,"elapsed":2094,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"8019d25e-0c4a-4366-a01b-e7ebeefdd202"},"source":["print(word_tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['The', 'capital', 'of', 'India', 'is', 'New', 'Delhi', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJH7cHjQOCAv"},"source":["text =  \"The capital of India is New Delhi. The capital of China is Beijing.\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C32Q413KM2z7"},"source":["**<h4>Question 4:** What if we want to tokenize sentences from paragraph?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Apply Sentence Tokenizer as **`nltk.sen_tokenize()`** on `text` variable.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"XnSa9_AwOCBA"},"source":["def tokenize_fn(text):\n","    sent_tokens = nltk.sent_tokenize(text)\n","\n","    return sent_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIlsQajIOCBH"},"source":["sent_tokens = tokenize_fn(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4cEu2r9aOCBO","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578387596021,"user_tz":-330,"elapsed":3087,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"81a0bf2b-6f4b-4f8d-d187-328b4fe44d82"},"source":["print(sent_tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['The capital of India is New Delhi.', 'The capital of China is Beijing.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-qKfIME6jvYP"},"source":["\n","<a id=section401></a>\n","### **4.3 Stopwords Removal**"]},{"cell_type":"markdown","metadata":{"id":"tnAULoLGjzdr"},"source":["- Stop words are a set of **commonly** used words in any language.\n","\n","- Stopwords usually don't provide **valuable** information for analysis.\n","\n","- The intuition behind not using **stop words** is that, by removing **low** information words from **text**, we can focus on the important words instead.\n","\n","- In English words like **\"i\", \"is\", \"was\", \"because\", \"him\"** are considered as **stopwords**.\n","\n","- For example if our input sentence is **`CEO is a cool guy`** then output after removing stopwords will be **`[CEO, cool, guy]`**."]},{"cell_type":"markdown","metadata":{"id":"6Dk416iNmCpF"},"source":["#### List of stopwords in English language:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"5Dext7B1mKDh","executionInfo":{"status":"ok","timestamp":1620739479680,"user_tz":-330,"elapsed":1421,"user":{"displayName":"Abhinav Jangir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5BRKsvqkQkWg693HbUASD9zTwMPl3TXIK2r0eNw=s64","userId":"14394398945056327842"}},"outputId":"c494ed25-50bb-42e9-dc77-5c3c671153f4"},"source":["\", \".join(stopwords.words('english'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"d5JwYL4tPaFS"},"source":["stopword = stopwords.words(\"english\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mh3Z17xBPaDC"},"source":["text =  \"The capital of India is New Delhi.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnHG-MZgPegP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578387900793,"user_tz":-330,"elapsed":1351,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"ba6f9956-d28c-4ad1-da0f-e11d3d29e451"},"source":["word_tokens = nltk.word_tokenize(text)\n","print(word_tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['The', 'capital', 'of', 'India', 'is', 'New', 'Delhi', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ddYTLq85O4Hj"},"source":["**<h4>Question 5:** How to remove stopwords from the text?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use **list comprehension** to remove words from `word_tokens` that are also in stopword list.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"o8SUMbBQPed4"},"source":["def stopword_removal(word_tokens):\n","    removing_stopwords = [word for word in word_tokens if word not in stopword]\n","\n","    return removing_stopwords"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSZPn-QvPMeN"},"source":["removing_stopwords = stopword_removal(word_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqI0y7i3PMbM","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578387916443,"user_tz":-330,"elapsed":1202,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"615af0ab-4260-4998-d9cc-02ca4dd1d943"},"source":["print(removing_stopwords)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['The', 'capital', 'India', 'New', 'Delhi', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ySknx-09m-oM"},"source":["<a id=section401></a>\n","### **4.4 Stemming**"]},{"cell_type":"markdown","metadata":{"id":"pjNSOlSQoysq"},"source":["- **Stemming** is the process of getting the **root form** of a word.\n","\n","- In stemming we **chops off** end of words to get their **root** form. \n","\n","- Root form can or can't be a **real word**. \n","\n","- Stemming is useful for dealing with **sparsity** issues as well as **standardizing** vocabulary.\n","\n","- For Example Words like **\"Connect\", \"Connects\", \"Connected\", \"Connections\",\"Connection\"** will be converted to **\"Connect\"**."]},{"cell_type":"code","metadata":{"id":"ohBW26xSRuN4"},"source":["snowball_stemmer = SnowballStemmer(\"english\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"66FyzpR7RuTN"},"source":["text = \"The athletes are running faster.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6s8MJ1cRuQ7"},"source":["word_tokens = nltk.word_tokenize(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3rtWSNMGQZVW"},"source":["**<h4>Question 6:** How to perform Stemming on a given corpus?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use Snowball stemmer as **`snowball_stemmer.stem()`** to apply stemming on `word_tokens`.\n","\n","- Perform tasks using list comprehension. \n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"1H9w7oB7RuLf"},"source":["def stemming_fn(word_tokens):\n","    stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]\n","\n","    return stemmed_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"poGLNiIbR4mV"},"source":["stemmed_word = stemming_fn(word_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jndtxiNoQbpu","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578388466003,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"5fc57287-8392-43d0-c458-cbc7de52718e"},"source":["print(stemmed_word)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['the', 'athlet', 'are', 'run', 'faster', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AaTpp2nMoVhc"},"source":["\n","<a id=section401></a>\n","### **4.5 Lemmatization**"]},{"cell_type":"markdown","metadata":{"id":"gBI_jN8P2DFK"},"source":["- Lemmatization process also converts words to their **reduced** form.\n","\n","- But unlike **Stemming**, Lemmatization converts words to **pre-existing** words in any language.\n","\n","- **Converted words**(Root Words) are called **Lemma**.\n","\n","- For example words **\"Troubles\", \"Troubling\", \"Troubled\", \"Trouble\"** can be reduced to word **\"Trouble\"**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Kb3Uy1nvdhcF"},"source":["<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/image/Sqweeks%20image/c71d705d-445d-4d4c-99d1-38ce48985cba_12.JPG\" width=\"800\" height=\"350\" /></center>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"id":"jE4TTCirn3kb","executionInfo":{"status":"ok","timestamp":1578388181699,"user_tz":-330,"elapsed":2202,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"f25eb40f-5a02-4018-c3bb-7c21769104cc"},"source":["nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"_S7FUiYLn3ki"},"source":["text = \"The athletes are running faster.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YegSqfV5n3kh"},"source":["wordnet_lemmatizer = WordNetLemmatizer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SGXJxacn3kj"},"source":["word_tokens = nltk.word_tokenize(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ouAZt0Z18eEb"},"source":["word_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pFmslvR0n3kY"},"source":["**<h4>Question 7:** How to perform perform Lemmatization on word corpus?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use Lemmatization using **`wordnet_lemmatizer.lemmatize()`** for text corpus.\n","\n","- Perform task using **list comprehension** method.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"38n2F0WVn3kk"},"source":["def lemmatization_fn(word_tokens):\n","    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n","\n","    return lemmatized_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsukE9Qan3km"},"source":["lemmatized_word = lemmatization_fn(word_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"o2mRHAqQn3ko","executionInfo":{"status":"ok","timestamp":1578388297866,"user_tz":-330,"elapsed":1097,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"664c613b-2588-4298-900f-502102cf4523"},"source":["print(lemmatized_word)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['The', 'athlete', 'are', 'running', 'faster', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ov7JY9n7WeNJ"},"source":["text = \"Twinkle, twinkle, little star, How I wonder what you are.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qADxgkrlWeP2"},"source":["word_tokens = nltk.word_tokenize(text.lower())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ExpBl6gbXZSM","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578389847197,"user_tz":-330,"elapsed":2557,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"6a1ded1e-3dc4-4a58-b5cd-ea76b1ca8fd3"},"source":["print(word_tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['twinkle', ',', 'twinkle', ',', 'little', 'star', ',', 'how', 'i', 'wonder', 'what', 'you', 'are', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hjKBXAj4SLT_"},"source":["**<h4>Question 8:** How to calculate the Word Frequency of each word in the text and print the n most common words?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use **`FreqDist()`** from NLTK for **text corpus** .\n","\n","- Use **`freq.most_comman()`** fuction with **n** as **parameter**.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"aXjdDYVWWeLS"},"source":["def word_frequency_fn(word_tokens):\n","    freq = FreqDist(word_tokens)\n","    \n","    print (freq.most_common(5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSQl0X8CWeIY","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578389856891,"user_tz":-330,"elapsed":1925,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"cd202c87-f8eb-420c-eaf4-76dddaf3d7b4"},"source":["word_frequency_fn(word_tokens)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[(',', 3), ('twinkle', 2), ('little', 1), ('star', 1), ('how', 1)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0akmIqCtFylC"},"source":["<a id=section401></a>\n","### **4.6 Part-of-Speech (POS) Tagging**"]},{"cell_type":"markdown","metadata":{"id":"E1NbiTnnF5z8"},"source":["\n","- **Part-of-speech**(POS) tagging is a process to **mark word** in a text **corpus** based on **definition** as well as its **context** and **sementic** **meaning**. \n","\n","- **Part-of-speech(POS)** tagging **aims** to assign parts of speech to each word of a given **text** **(such as nouns, verbs, adjectives, and others)**. \n","\n","- For example sentence **`\"the kids are playing in the park.\"`** will give output as **follows** after applying **POS**:\n","\n","**`[('the', 'DT'), ('kids', 'NNS'), ('are', 'VBP'), ('playing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('park', 'NN'), ('.', '.')]`**\n","\n","#### POS tag list:\n","\n","\n","    CC\t  coordinating conjunction\n","    CD\t  cardinal digit\n","    DT\t  determiner\n","    IN\t  preposition/subordinating conjunction\n","    JJ\t  adjective\n","    JJR\t  adjective, comparative\n","    JJS\t  adjective, superlative\n","    MD\t  modal\t\n","    NN\t  noun, singular\n","    NNS\t  noun plural\n","    NNP\t  proper noun, singular\n","    NNPS\tproper noun, plural\n","    PDT \tpredeterminer\n","    POS \tpossessive ending\t\n","    PRP \tpersonal pronoun\n","    PRP$\tpossessive pronoun\n","    RB\t  adverb\n","    RBR  \tadverb, comparative\n","    RBS  \tadverb, superlative\n","    RP  \tparticl\n","    UH  \tinterjection\n","    VB  \tverb\n","    VBD  \tverb, past tense\n","    VBG \tverb, gerund/present participle\n","    VBN  \tverb, past participle\n","    VBP \tverb, present\n","    VBZ \tverb, 3rd person\n","    WDT \twh-determiner\n"]},{"cell_type":"code","metadata":{"id":"W8SX1-yMX3mc","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1578390067854,"user_tz":-330,"elapsed":3761,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"bb477aab-b89f-4305-e783-f15d8c7a26a1"},"source":["nltk.download('averaged_perceptron_tagger')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"atVowSaRX3rh"},"source":["text = \"the kids are playing in the park.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AHRijXDbX3pt"},"source":["word_tokens = nltk.word_tokenize(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmLcWZOaW7OB"},"source":["**<h4>Question 9:** How to perform POS (Part of Speech) Tagging?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use **`nltk.pos_tag()`** with `word_tokens` as parameter to apply POS.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"4cL8T89EX79n"},"source":["def pos_tagging(word_tokens):\n","    pos_tag = nltk.pos_tag(word_tokens)\n","\n","    return pos_tag"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJezeJ1lX8AV"},"source":["pos_tag = pos_tagging(word_tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnMWl6fMYPmX","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1578390162954,"user_tz":-330,"elapsed":714,"user":{"displayName":"Mohit Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWeTZUrbhhCiZ-3HbrA91YVJTlW3olUgVSeOr8Ww=s64","userId":"17943522262909727589"}},"outputId":"a8b0c242-056c-4547-d636-372a382e13aa"},"source":["print(pos_tag)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('the', 'DT'), ('kids', 'NNS'), ('are', 'VBP'), ('playing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('park', 'NN'), ('.', '.')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q1nHZ_wt8nFp"},"source":["**Observation:**\n","\n","Here,\n","\n","- **\"DT\"** corresponds to **Determiner**\n","- **\"NNS\"** tag corresponds to **Noun Plural**\n","- **\"VBP\"** tag corresponds to **Verb, Present** \n","- **\"IN\"** tag corresponds to **Preposition**\n","- **\"NN\"** tag corrensponds to **Noun, Singular**"]},{"cell_type":"markdown","metadata":{"id":"KRSkwxUSNENG"},"source":["----\n","<a id=section5></a>\n","# **5. Name Entity Recognition**\n","----"]},{"cell_type":"markdown","metadata":{"id":"afqPYC2lQL65"},"source":["- The aim of Name Entity Recognition is to **find** and **classify** named entities in text into pre-defined **categories** such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.\n","\n","- NER can be **useful** in applications like Classifying content for news providers, Summarizing Resumes, Optimizing Search Engine Algorithms, Simplifying Customer Support. \n"]},{"cell_type":"code","metadata":{"id":"7BHOS6MUZGou"},"source":["text = \"New Delhi is the capital of India. Beijing is the capital of China.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DvkpDbIZGtT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620752998031,"user_tz":-330,"elapsed":1322,"user":{"displayName":"Abhinav Jangir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5BRKsvqkQkWg693HbUASD9zTwMPl3TXIK2r0eNw=s64","userId":"14394398945056327842"}},"outputId":"66eb16db-e0bd-4102-c9a7-3e96ba8ce65b"},"source":["# Tokenize the input text \n","word_tokens = nltk.word_tokenize(text)\n","word_tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['New',\n"," 'Delhi',\n"," 'is',\n"," 'the',\n"," 'capital',\n"," 'of',\n"," 'India',\n"," '.',\n"," 'Beijing',\n"," 'is',\n"," 'the',\n"," 'capital',\n"," 'of',\n"," 'China',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"KgZ-lbGEaM3p"},"source":["**Observation:**\n","\n","- We get a list of containing the **individual tokenized** words in the sentence."]},{"cell_type":"code","metadata":{"id":"5ibXeSyPZOWG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620753034686,"user_tz":-330,"elapsed":1208,"user":{"displayName":"Abhinav Jangir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5BRKsvqkQkWg693HbUASD9zTwMPl3TXIK2r0eNw=s64","userId":"14394398945056327842"}},"outputId":"464306c2-93b7-465f-d702-891684c8abbc"},"source":["#Applying POS Tagging\n","pos_tag = nltk.pos_tag(word_tokens)\n","pos_tag"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('New', 'NNP'),\n"," ('Delhi', 'NNP'),\n"," ('is', 'VBZ'),\n"," ('the', 'DT'),\n"," ('capital', 'NN'),\n"," ('of', 'IN'),\n"," ('India', 'NNP'),\n"," ('.', '.'),\n"," ('Beijing', 'NNP'),\n"," ('is', 'VBZ'),\n"," ('the', 'DT'),\n"," ('capital', 'NN'),\n"," ('of', 'IN'),\n"," ('China', 'NNP'),\n"," ('.', '.')]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"UzGS22_y9Zk_"},"source":["**Observation:**\n","\n","- We got a list of words with **part of speech**(pos) tag."]},{"cell_type":"markdown","metadata":{"id":"e2WNykdTaTgU"},"source":["- Now we’ll implement **noun phrase** **chunking** to identify **named entities** using a **regular expression** consisting of rules that **indicate** how sentences should be **chunked**."]},{"cell_type":"markdown","metadata":{"id":"sKdkOGFxYy4b"},"source":["**<h4>Question 10:** How to perform NER (Named Entity Recognition) using NLTK library?</h4>\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use **`nltk.ne_chunk()`** to perform NER..\n","\n","- Give `pos_tag` as parameter.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"lOru1OP6ZObA"},"source":["chunk = nltk.ne_chunk(pos_tag)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4piXFIoZOZP"},"source":["def ner_fn(chunk):\n","    NE = [ \" \".join(w for w, t in ele) for ele in chunk if isinstance(ele, nltk.Tree)]\n","\n","    return NE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F11IytU8ZUEL"},"source":["NE = ner_fn(chunk)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJ0iTq3nZGro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620753190257,"user_tz":-330,"elapsed":709,"user":{"displayName":"Abhinav Jangir","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5BRKsvqkQkWg693HbUASD9zTwMPl3TXIK2r0eNw=s64","userId":"14394398945056327842"}},"outputId":"e0e2ea60-c572-490d-ac16-063db9f84c05"},"source":["print(NE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['New Delhi', 'India', 'Beijing', 'China']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fGV1HKpn9mHC"},"source":["**Observation:**\n","\n","- We got list of **Name entities** present in input text."]},{"cell_type":"markdown","metadata":{"id":"eCkguotlbJNG"},"source":["----\n","<a id=section6></a>\n","# **6. Conclusion**\n","----"]},{"cell_type":"markdown","metadata":{"id":"hhbh965UbNEG"},"source":["- **NER** gives us detailed knowledge about the **text** and the relationships between the **different entities**.\n","\n","- It is not **necessary** to apply all text **preprocessing techniques** on **NLP** tasks.\n","\n","- The pre-processing steps for a **problem** depend **mainly** on the **domain** and the **problem**.\n","\n","- Apply moderate pre-processing if you have a lot of **noisy data**, or if you have good quality text but a **scarcity** of data. When the **data** is **sparse**, heavy text pre-processing is needed. \n","\n","- NER can be **useful** in applications like **Classifying content for news providers**, **Summarizing Resumes**, **Optimizing Search Engine Algorithms**, **Simplifying Customer Support**."]}]}